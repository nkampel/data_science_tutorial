{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMZvWFiN1fx4s0Un9vq3mo3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nkampel/data_science_tutorial/blob/main/Profiling_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary libraries\n",
        "!pip install transformers\n",
        "!pip install braindecode"
      ],
      "metadata": {
        "id": "lL8mUwDmnx94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import GPT2Model, GPT2Config\n",
        "from braindecode.models import EEGInceptionMI\n",
        "\n",
        "class EncoderEEGModel(nn.Module):\n",
        "    def __init__(self, n_chans, n_outputs, input_window_seconds, sfreq):\n",
        "        super(EncoderEEGModel, self).__init__()\n",
        "        # Define your EEG encoder model here\n",
        "        self.eeg_model = EEGInceptionMI(n_chans, n_outputs, input_window_seconds, sfreq, add_log_softmax=False)\n",
        "\n",
        "    def forward(self, eeg_data):\n",
        "        # Forward pass of EEG encoder\n",
        "        eeg_output = self.eeg_model(eeg_data)\n",
        "        return eeg_output\n",
        "\n",
        "class CombinedModel(nn.Module):\n",
        "    def __init__(self, eeg_model, gpt2_model):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.eeg_model = eeg_model\n",
        "        self.gpt2_model = gpt2_model\n",
        "\n",
        "    def forward(self, eeg_data):\n",
        "        # Forward pass of EEG model\n",
        "        eeg_output = self.eeg_model(eeg_data)\n",
        "        # Forward pass of GPT-2 model\n",
        "        gpt2_output = self.gpt2_model(inputs_embeds=eeg_output)\n",
        "        return gpt2_output\n",
        "\n",
        "\n",
        "\n",
        "# Initialize your EEG model\n",
        "n_chans = 22\n",
        "n_outputs = 768\n",
        "input_window_seconds = 4.5\n",
        "sfreq = 250\n",
        "n_times = int(4.5*250)\n",
        "\n",
        "\n",
        "eeg_model = EncoderEEGModel(n_chans, n_outputs, input_window_seconds, sfreq)\n",
        "\n",
        "# Initialize GPT-2 model\n",
        "gpt2_config = GPT2Config.from_pretrained(\"gpt2\")\n",
        "gpt2_model = GPT2Model(gpt2_config)\n",
        "\n",
        "# Initialize combined model\n",
        "combined_model = CombinedModel(eeg_model, gpt2_model)\n",
        "\n",
        "# Example usage:\n",
        "eeg_data = torch.randn(1, n_chans, n_times)  # Example EEG data, shape: [batch_size, n_chans, n_times]\n",
        "output = combined_model(eeg_data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "Qe8ft3HvoGMH",
        "outputId": "2232230f-f1b5-4eba-dcc6-fd105d99e230"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-1ca0afcf4b2a>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0meeg_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meeg_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meeg_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mgpt_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meeg_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    838\u001b[0m         \u001b[0mposition_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2233\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import GPT2Config, GPT2Model\n",
        "from braindecode.models import EEGInceptionMI\n",
        "\n",
        "class EncoderEEGModel(nn.Module):\n",
        "    def __init__(self, n_chans, n_outputs, input_window_seconds, sfreq):\n",
        "        super(EncoderEEGModel, self).__init__()\n",
        "        # Define your EEG encoder model here\n",
        "        self.eeg_model = EEGInceptionMI(n_chans, n_outputs, input_window_seconds, sfreq, add_log_softmax=False)\n",
        "\n",
        "    def forward(self, eeg_data):\n",
        "        # Forward pass of EEG encoder\n",
        "        eeg_output = self.eeg_model(eeg_data)\n",
        "        return eeg_output\n",
        "\n",
        "class CombinedModel(nn.Module):\n",
        "    def __init__(self, eeg_model, gpt2_embedding_size, n_gpt2_blocks=12):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.eeg_model = eeg_model\n",
        "        self.gpt2_model = self.initialize_gpt2_model(gpt2_embedding_size, n_gpt2_blocks)\n",
        "        self.embedding_size = gpt2_embedding_size\n",
        "\n",
        "    def initialize_gpt2_model(self, gpt2_embedding_size, n_gpt2_blocks):\n",
        "        # Initialize GPT-2 model from scratch\n",
        "        gpt2_config = GPT2Config(n_layer=n_gpt2_blocks, n_embd=gpt2_embedding_size)\n",
        "        gpt2_model = GPT2Model(gpt2_config)\n",
        "        return gpt2_model\n",
        "\n",
        "    def forward(self, eeg_data):\n",
        "        # Forward pass of EEG model\n",
        "        eeg_output = self.eeg_model(eeg_data)\n",
        "\n",
        "        # Resize EEG output to match the embedding size of GPT-2\n",
        "        eeg_output_resized = eeg_output.unsqueeze(1).expand(-1, eeg_output.size(1), self.embedding_size)\n",
        "\n",
        "        # Forward pass of GPT-2 model\n",
        "        gpt2_output = self.gpt2_model(inputs_embeds=eeg_output_resized)\n",
        "        return gpt2_output\n",
        "\n",
        "# Example usage:\n",
        "n_chans = 22\n",
        "n_outputs = 768\n",
        "input_window_seconds = 4.5\n",
        "sfreq = 250\n",
        "n_times = int(4.5 * 250)\n",
        "n_gpt2_blocks = 6\n",
        "gpt2_embedding_size = 768  # Match the embedding size of the GPT-2 model\n",
        "\n",
        "eeg_model = EncoderEEGModel(n_chans, n_outputs, input_window_seconds, sfreq)\n",
        "combined_model = CombinedModel(eeg_model, gpt2_embedding_size, n_gpt2_blocks)\n",
        "\n",
        "# Example usage:\n",
        "eeg_data = torch.randn(1, n_chans, n_times)  # Example EEG data, shape: [batch_size, n_chans, n_times]\n",
        "output = combined_model(eeg_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "0V1niUdS1Vjg",
        "outputId": "e04c558c-0243-4bb9-d73e-7f1ce49ab74f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The expanded size of the tensor (384) must match the existing size (768) at non-singleton dimension 2.  Target sizes: [-1, 768, 384].  Tensor sizes: [1, 1, 768]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-65899912f28e>\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0meeg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_chans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_times\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Example EEG data, shape: [batch_size, n_chans, n_times]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meeg_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-65899912f28e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, eeg_data)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Resize EEG output to match the embedding size of GPT-2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0meeg_output_resized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meeg_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meeg_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Forward pass of GPT-2 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (384) must match the existing size (768) at non-singleton dimension 2.  Target sizes: [-1, 768, 384].  Tensor sizes: [1, 1, 768]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgBxQsGJ2f5B",
        "outputId": "ed6aeb44-75c8-4c6f-9dfc-334cc1e0e918"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CombinedModel(\n",
              "  (eeg_model): EncoderEEGModel(\n",
              "    (eeg_model): EEGInceptionMI(\n",
              "      (activation): ReLU()\n",
              "      (ensuredims): Ensure4d()\n",
              "      (dimshuffle): Rearrange('batch C T 1 -> batch C 1 T')\n",
              "      (initial_inception_module): _InceptionModuleMI(\n",
              "        (bottleneck): Conv2d(22, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (pooling): MaxPool2d(kernel_size=(1, 25), stride=1, padding=(0, 12), dilation=1, ceil_mode=False)\n",
              "        (pooling_conv): Conv2d(22, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (conv_list): ModuleList(\n",
              "          (0): Conv2d(48, 48, kernel_size=(1, 25), stride=(1, 1), padding=same)\n",
              "          (1): Conv2d(48, 48, kernel_size=(1, 75), stride=(1, 1), padding=same)\n",
              "          (2): Conv2d(48, 48, kernel_size=(1, 125), stride=(1, 1), padding=same)\n",
              "          (3): Conv2d(48, 48, kernel_size=(1, 175), stride=(1, 1), padding=same)\n",
              "          (4): Conv2d(48, 48, kernel_size=(1, 225), stride=(1, 1), padding=same)\n",
              "        )\n",
              "        (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (intermediate_inception_modules_1): ModuleList(\n",
              "        (0-1): 2 x _InceptionModuleMI(\n",
              "          (bottleneck): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (pooling): MaxPool2d(kernel_size=(1, 25), stride=1, padding=(0, 12), dilation=1, ceil_mode=False)\n",
              "          (pooling_conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (conv_list): ModuleList(\n",
              "            (0): Conv2d(48, 48, kernel_size=(1, 25), stride=(1, 1), padding=same)\n",
              "            (1): Conv2d(48, 48, kernel_size=(1, 75), stride=(1, 1), padding=same)\n",
              "            (2): Conv2d(48, 48, kernel_size=(1, 125), stride=(1, 1), padding=same)\n",
              "            (3): Conv2d(48, 48, kernel_size=(1, 175), stride=(1, 1), padding=same)\n",
              "            (4): Conv2d(48, 48, kernel_size=(1, 225), stride=(1, 1), padding=same)\n",
              "          )\n",
              "          (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (residual_block_1): _ResidualModuleMI(\n",
              "        (activation): ReLU()\n",
              "        (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv): Conv2d(22, 288, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (intermediate_inception_modules_2): ModuleList(\n",
              "        (0-2): 3 x _InceptionModuleMI(\n",
              "          (bottleneck): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (pooling): MaxPool2d(kernel_size=(1, 25), stride=1, padding=(0, 12), dilation=1, ceil_mode=False)\n",
              "          (pooling_conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (conv_list): ModuleList(\n",
              "            (0): Conv2d(48, 48, kernel_size=(1, 25), stride=(1, 1), padding=same)\n",
              "            (1): Conv2d(48, 48, kernel_size=(1, 75), stride=(1, 1), padding=same)\n",
              "            (2): Conv2d(48, 48, kernel_size=(1, 125), stride=(1, 1), padding=same)\n",
              "            (3): Conv2d(48, 48, kernel_size=(1, 175), stride=(1, 1), padding=same)\n",
              "            (4): Conv2d(48, 48, kernel_size=(1, 225), stride=(1, 1), padding=same)\n",
              "          )\n",
              "          (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (residual_block_2): _ResidualModuleMI(\n",
              "        (activation): ReLU()\n",
              "        (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (ave_pooling): AvgPool2d(kernel_size=(1, 1125), stride=(1, 1125), padding=0)\n",
              "      (flat): Flatten(start_dim=1, end_dim=-1)\n",
              "      (final_layer): Sequential(\n",
              "        (fc): Linear(in_features=288, out_features=768, bias=True)\n",
              "        (out_fun): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (gpt2_model): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-5): 6 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A0E_S7Tc2gBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2UJZexFI2gD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f2Kr4uI-2gGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gKQyzxPc2gIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "eeg_data = torch.randn(1, n_chans, n_times)  # Example EEG data, shape: [batch_size, n_chans, n_times]\n",
        "output = combined_model(eeg_data)\n",
        "\n",
        "# Get the output from the EEG model\n",
        "eeg_output = eeg_model(eeg_data)\n",
        "\n",
        "# Manually embed the output of the EEG model\n",
        "# You may need to adjust this step based on the specific requirements of your GPT-2 model\n",
        "# Here, we assume that the EEG output can be directly used as input embeddings for the GPT-2 model\n",
        "embedded_output = eeg_output\n",
        "\n",
        "# Forward pass of GPT-2 model with the embedded EEG output\n",
        "gpt_output = gpt2_model(inputs_embeds=embedded_output)\n",
        "\n",
        "outputs_different = not torch.allclose(eeg_output[0], gpt_output[0])\n",
        "\n",
        "if outputs_different:\n",
        "    print(\"The outputs of the EEG model and the GPT-2 model are different.\")\n",
        "else:\n",
        "    print(\"The outputs of the EEG model and the GPT-2 model are the same.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li2vpxL-zF4V",
        "outputId": "fa74a758-6384-47f2-9c0a-a8cc643b49e4"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The outputs of the EEG model and the GPT-2 model are different.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_output[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9DJxhXqy8A9",
        "outputId": "b7d6aa64-fe03-46cb-d00f-382efe43e621"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "eeg_data = torch.randn(1, n_chans, n_times)  # Example EEG data, shape: [batch_size, n_chans, n_times]\n",
        "output = combined_model(eeg_data)\n",
        "\n",
        "# Print the shapes of individual tensors in the output tuple\n",
        "for i, tensor in enumerate(output[1]):\n",
        "    print(f\"GPT-2 Model Output Tensor {i} Shape:\", tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "fJ5nOnxFyzWp",
        "outputId": "ce0954d3-0b43-4c29-b63c-31269bc52c9e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-44a5ecf99472>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Print the shapes of individual tensors in the output tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"GPT-2 Model Output Tensor {i} Shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize your EEG model\n",
        "n_chans = 22\n",
        "n_outputs = 768\n",
        "input_window_seconds = 4.5\n",
        "sfreq = 250\n",
        "n_times = int(4.5*250)\n",
        "\n",
        "\n",
        "eeg_model = EncoderEEGModel(n_chans, n_outputs, input_window_seconds, sfreq)\n",
        "\n",
        "# Initialize GPT-2 model\n",
        "gpt2_config = GPT2Config.from_pretrained(\"gpt2\")\n",
        "gpt2_model = GPT2Model(gpt2_config)\n",
        "\n",
        "# Initialize combined model\n",
        "combined_model = CombinedModel(eeg_model, gpt2_model)\n",
        "\n",
        "# Example usage:\n",
        "eeg_data = torch.randn(1, n_chans, n_times)  # Example EEG data, shape: [batch_size, n_chans, n_times]\n",
        "output = combined_model(eeg_data)\n",
        "\n",
        "print(f\"GPT-2 Model Output Tensor Shape:\", output[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IS5wW9boUGH",
        "outputId": "90e1b488-9810-4ce5-d596-34438c383a91"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT-2 Model Output Tensor Shape: torch.Size([1, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, tensor in enumerate(output[1]):\n",
        "    print(f\"GPT-2 Model Output Tensor {i} Shape:\", tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "X4E1C25VwBzx",
        "outputId": "52d3845d-6436-40e0-fe0d-a04943072c4d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-b7a17834b9a2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"GPT-2 Model Output Tensor {i} Shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9dkZb0XwB3i",
        "outputId": "c81371c1-e18d-4b2f-a7b3-f3b055d343c8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "11vLYV4twB-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BRNVfiLlwCAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchviz import make_dot\n",
        "\n",
        "# Visualize EEG model\n",
        "eeg_output = eeg_model(torch.randn(1, n_chans, n_times))\n",
        "make_dot(eeg_output, params=dict(eeg_model.named_parameters())).render(\"eeg_model\", format=\"png\")\n",
        "\n",
        "# Visualize GPT-2 model with EEG embeddings\n",
        "gpt2_output = gpt2_model(inputs_embeds=eeg_output)\n",
        "make_dot(gpt2_output, params=dict(gpt2_model.named_parameters())).render(\"gpt2_model\", format=\"png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "8UTgMroeficH",
        "outputId": "568e2071-4c47-43c0-d156-789c9a07d81b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unhashable type: 'BaseModelOutputWithPastAndCrossAttentions'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-2106c49e22d2>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Visualize GPT-2 model with EEG embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgpt2_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meeg_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmake_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpt2_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpt2_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gpt2_model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchviz/dot.py\u001b[0m in \u001b[0;36mmake_dot\u001b[0;34m(var, params, show_attrs, show_saved, max_attr_chars)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0madd_base_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0madd_base_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mresize_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchviz/dot.py\u001b[0m in \u001b[0;36madd_base_tensor\u001b[0;34m(var, color)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_base_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'darkolivegreen1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mseen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'BaseModelOutputWithPastAndCrossAttentions'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eeg_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrBx3hIautoK",
        "outputId": "85d0512a-1394-441f-c92a-1d23ae9a9a0b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.5136e-01, -1.2143e+00, -4.8543e-01, -4.8605e-01,  9.9775e-02,\n",
              "         -8.2560e-01,  3.3995e-01, -4.9248e-01,  1.3174e-01,  5.9843e-01,\n",
              "          4.3467e-01, -3.3816e-01, -6.4134e-01, -3.0705e-02, -1.4262e-01,\n",
              "          1.0825e-01,  8.6665e-02, -2.1842e-01, -2.3456e-01,  3.0020e-01,\n",
              "          2.2166e-01,  6.6923e-01, -3.1276e-01, -2.2700e-01, -2.0324e-01,\n",
              "         -6.9813e-01,  1.4384e-01, -1.5111e-01,  3.4685e-01, -3.2506e-01,\n",
              "          8.0895e-01, -1.1485e+00,  4.3543e-01, -6.8292e-01, -3.5660e-01,\n",
              "          1.7431e-01, -7.9292e-01,  8.1750e-02, -5.0028e-01,  9.1045e-01,\n",
              "         -6.4724e-02, -4.9543e-01, -5.5367e-02,  6.6174e-01,  3.8639e-02,\n",
              "          1.6639e-01, -1.3916e-01, -2.2760e-02, -4.1277e-02, -3.0376e-02,\n",
              "         -9.7262e-03, -5.2796e-01, -4.1267e-01, -6.0717e-01,  7.2121e-02,\n",
              "         -9.0183e-02,  6.0659e-03,  8.6592e-01, -5.7494e-01,  2.5092e-01,\n",
              "          8.9376e-02, -4.8503e-02, -4.7481e-01, -7.0623e-02, -1.4292e-01,\n",
              "          7.5085e-02, -3.4870e-01,  1.5525e-01,  4.5337e-01,  1.1218e-01,\n",
              "          8.4181e-02,  6.2393e-02, -5.9914e-01,  2.5818e-01, -8.4689e-02,\n",
              "          1.7266e-01,  9.0483e-01,  5.4407e-02,  4.3133e-01,  4.2547e-01,\n",
              "         -1.6081e-01,  1.3645e-01,  6.3480e-01,  7.0909e-01,  1.6543e-01,\n",
              "          7.1087e-01,  2.4053e-01,  3.0445e-01,  1.4369e+00,  1.9615e-01,\n",
              "         -2.0691e-01, -6.0639e-01,  4.1198e-02,  4.5370e-01,  2.1504e-01,\n",
              "          9.1818e-02,  2.1684e-02, -1.2301e+00,  2.1037e-01, -3.1615e-01,\n",
              "         -2.2019e-01, -2.8086e-01, -1.3341e-01,  1.4480e-01, -2.9470e-01,\n",
              "         -4.0001e-01, -3.7239e-01,  1.5213e-01,  3.1824e-01, -6.0529e-01,\n",
              "          1.5160e-02,  4.4839e-01,  1.1572e-02, -3.6039e-02,  4.4399e-01,\n",
              "         -6.6571e-01, -7.5212e-01, -1.0578e+00, -1.9875e-01,  2.2526e-01,\n",
              "          6.2014e-01, -3.2933e-01, -3.1729e-01,  8.7325e-01,  7.7362e-02,\n",
              "          7.8232e-01,  4.8579e-01,  5.8446e-01, -1.6109e-01,  9.9160e-02,\n",
              "          1.8282e-01,  3.2920e-01,  5.7946e-01, -1.5254e-01,  2.3028e-01,\n",
              "         -2.0689e-01,  7.3623e-01,  8.9302e-01,  3.0519e-01, -1.6027e-01,\n",
              "          2.2354e-01,  6.2604e-01,  7.9658e-01,  9.4763e-01, -7.2184e-02,\n",
              "         -4.2820e-01, -9.0580e-01, -5.3011e-01,  5.9569e-01,  5.5185e-01,\n",
              "          2.2557e-01, -2.6961e-01, -5.7897e-02,  2.3434e-01, -3.1341e-01,\n",
              "         -2.5436e-01, -7.1418e-01,  6.0535e-02,  3.1513e-01, -4.8218e-01,\n",
              "         -1.5180e-03,  3.6591e-01,  6.1006e-01,  8.1741e-02,  4.1147e-01,\n",
              "          4.6129e-01,  8.1427e-01, -1.1591e-01, -3.6014e-01,  4.1289e-02,\n",
              "          3.8379e-03,  6.7619e-03, -5.8778e-01, -3.9866e-01,  5.1891e-01,\n",
              "          4.9714e-01, -7.0819e-02, -2.9444e-01,  1.3956e-01, -2.8697e-01,\n",
              "         -1.1528e-01,  2.6593e-01,  7.8061e-02,  3.4676e-01,  1.0430e-01,\n",
              "         -4.8297e-01,  8.0897e-01, -1.3412e-01, -8.6016e-02,  1.0830e-01,\n",
              "         -1.0171e+00,  3.3189e-01,  9.4520e-02, -3.6699e-01,  1.2538e-01,\n",
              "          6.1177e-01,  4.2132e-01, -3.5428e-01, -5.5454e-01,  9.9575e-02,\n",
              "          4.1013e-01, -3.1801e-01, -8.0076e-01, -5.1734e-02, -1.3560e-01,\n",
              "          4.4579e-01, -4.3585e-01, -4.4857e-01,  3.4891e-01,  3.8179e-01,\n",
              "         -4.3388e-01, -2.1853e-02,  2.8703e-01, -1.3819e-01,  2.2306e-01,\n",
              "         -6.7331e-01, -3.6237e-01, -6.1398e-01,  6.4194e-02, -2.6038e-01,\n",
              "          2.7507e-01, -2.5228e-01, -1.9682e-01,  5.1182e-01, -3.4741e-01,\n",
              "          8.2225e-03, -5.4175e-01, -9.4202e-02,  2.7044e-01,  2.5893e-01,\n",
              "          8.7043e-02, -6.9146e-01, -2.9354e-01,  3.4479e-01,  2.0050e-01,\n",
              "         -5.5676e-02,  4.4055e-02, -1.6962e-01, -1.9227e-01,  3.8763e-01,\n",
              "          2.0860e-02,  1.6712e-01, -1.6571e-01,  6.3084e-01, -1.4666e+00,\n",
              "         -2.0161e-01, -2.4654e-01, -8.5118e-01,  4.8079e-01,  6.6695e-01,\n",
              "         -6.6655e-02, -5.9864e-01,  5.8243e-01,  2.6301e-01,  1.7545e-01,\n",
              "         -1.9911e-01,  1.4251e-01,  8.9576e-01,  9.4989e-01, -5.8634e-01,\n",
              "          6.5941e-02, -4.2444e-01,  9.4728e-01, -3.2719e-01,  6.4151e-01,\n",
              "          5.3467e-01,  2.9108e-01,  4.1430e-01, -1.1230e-01, -1.9096e-02,\n",
              "          1.1135e-01, -9.8070e-02,  2.0959e-01,  4.6018e-01, -8.0149e-01,\n",
              "         -6.7760e-01, -7.8802e-01,  2.5855e-01,  3.2938e-01,  1.1689e-01,\n",
              "          1.3930e-01, -3.6860e-02, -1.3026e-03, -6.4200e-01,  1.1862e-01,\n",
              "          5.1922e-01,  3.2929e-01,  1.0606e+00,  7.3998e-01, -3.4847e-02,\n",
              "          3.3606e-01, -5.0248e-01, -1.3078e+00,  1.8402e-01,  3.2373e-01,\n",
              "         -2.2327e-01,  2.3250e-01,  1.8828e-01,  2.8550e-01, -4.4162e-01,\n",
              "         -1.2120e-01,  4.4503e-01, -3.8143e-03,  2.7829e-01,  4.8880e-01,\n",
              "         -6.5242e-01, -2.8493e-01, -2.5615e-01,  4.2256e-01,  5.0363e-01,\n",
              "          2.3914e-01,  7.7638e-02,  2.4829e-01, -4.1088e-01,  9.9365e-01,\n",
              "         -9.8160e-01,  7.4349e-01, -1.1866e-01,  2.8663e-01, -2.8115e-01,\n",
              "         -1.0031e+00, -3.2173e-01, -4.6511e-02,  1.1218e-01, -1.1987e-01,\n",
              "          5.0166e-01, -6.1394e-01, -4.4805e-01, -5.7806e-02, -2.3353e-01,\n",
              "          1.1403e-01, -1.3449e-01,  5.9022e-01,  3.2265e-01,  9.4909e-01,\n",
              "          2.5037e-01, -5.3511e-01, -6.2892e-02, -3.1279e-01, -5.9310e-01,\n",
              "          2.3886e-02,  1.2678e-01,  1.1565e-02, -7.7986e-01,  5.6014e-01,\n",
              "          5.9575e-01, -2.7430e-01, -6.4451e-01,  3.0994e-01,  1.8179e-01,\n",
              "         -1.2871e-01,  4.7842e-01, -7.3386e-01, -8.4065e-02,  3.7574e-01,\n",
              "         -6.7233e-01,  1.4616e-01, -3.2856e-01,  6.1730e-01, -4.9719e-01,\n",
              "         -4.0640e-01, -9.8719e-01, -1.3046e-01,  3.8867e-01,  2.3344e-01,\n",
              "          4.4136e-01,  2.0533e-01, -4.2501e-02,  6.5192e-01, -2.3441e-01,\n",
              "          1.7543e-01,  3.5072e-02, -1.0629e-01, -4.3576e-01,  5.8854e-01,\n",
              "          3.0865e-01,  2.9793e-01, -4.3225e-01, -7.4967e-01,  1.5133e-02,\n",
              "         -5.9754e-02, -2.1946e-01,  5.7289e-01,  2.1776e-01, -6.7738e-01,\n",
              "          3.7441e-01,  3.0052e-01, -8.6093e-02,  8.0674e-01,  6.1023e-01,\n",
              "         -7.6001e-02,  9.1319e-01, -1.5768e-01,  4.7248e-02,  8.3374e-02,\n",
              "         -4.4764e-01,  1.6163e-02,  7.6700e-01,  4.1599e-01, -6.4178e-01,\n",
              "         -1.2604e-01,  5.0292e-01, -2.4637e-01,  4.3191e-01,  4.1831e-01,\n",
              "          7.6040e-02, -6.3101e-01, -2.5296e-01,  5.1074e-01,  7.1646e-02,\n",
              "         -4.3619e-01, -2.3269e-01,  7.0234e-01,  3.8886e-01,  7.7430e-01,\n",
              "          4.5498e-01, -7.5952e-02,  1.3096e-01,  4.1820e-01,  1.4367e+00,\n",
              "          4.6482e-01,  2.3585e-02,  5.9422e-02,  9.4401e-01, -1.7887e-01,\n",
              "         -3.0170e-02, -4.5440e-01,  4.8987e-01, -1.2365e-01,  5.6011e-01,\n",
              "         -1.8421e-01, -1.4480e-01,  8.4481e-02, -2.8937e-02,  2.0134e-01,\n",
              "         -6.1143e-01,  4.8551e-01,  6.7357e-02, -3.9559e-01,  4.4047e-01,\n",
              "          7.6634e-01, -5.4558e-01,  5.5789e-01, -2.0017e-01, -5.8338e-01,\n",
              "          1.0215e-01,  3.9289e-01, -8.9814e-01,  9.5268e-01,  2.6335e-01,\n",
              "         -4.1330e-01, -3.3016e-01, -2.2821e-02, -4.3892e-01,  6.9415e-01,\n",
              "          8.0959e-02,  3.8193e-01, -1.9861e-01, -8.9755e-02, -6.7628e-01,\n",
              "          6.9749e-03, -1.0474e+00,  1.9484e-01, -2.0606e-01, -1.0547e-01,\n",
              "          5.5904e-01, -8.1537e-02,  3.8593e-01, -6.5045e-02, -8.7708e-01,\n",
              "          9.0104e-02, -1.1879e+00, -2.4182e-01,  2.7081e-01,  9.1933e-01,\n",
              "          1.2085e-01,  7.6147e-01,  1.2217e-01, -1.9793e-01, -3.8505e-01,\n",
              "          3.7785e-01,  1.1609e-01,  7.3650e-01,  3.6723e-01,  5.3322e-01,\n",
              "         -4.8837e-01, -3.3312e-01,  2.4131e-01,  1.0119e+00,  6.8632e-01,\n",
              "         -2.0047e-01, -1.2096e+00,  2.0552e-02, -6.0791e-01,  5.0489e-01,\n",
              "         -1.1444e-01, -2.5093e-01,  2.7671e-03,  2.4889e-01,  5.3731e-01,\n",
              "         -5.2979e-01,  6.5090e-01,  3.5235e-01, -1.4935e-01,  3.5620e-02,\n",
              "          5.9881e-02,  6.7190e-01, -6.1898e-01,  1.4866e-01,  4.1852e-01,\n",
              "         -5.0963e-01,  4.4070e-01,  4.5206e-01,  4.7424e-01,  6.8136e-01,\n",
              "         -8.6202e-01,  5.1497e-01, -1.1157e-01, -8.8784e-02,  1.3727e-01,\n",
              "          1.1902e+00, -2.5255e-02, -9.2368e-01, -3.8892e-01,  1.4275e-01,\n",
              "          1.2319e-02, -3.0513e-01,  8.5495e-01,  1.0334e-01,  2.7980e-01,\n",
              "         -6.9380e-01, -5.4029e-01,  2.8408e-01,  3.5930e-01, -4.1822e-01,\n",
              "         -1.3836e-01, -1.0782e-01, -2.0191e-01, -3.3666e-01, -2.9495e-01,\n",
              "         -4.3892e-01,  3.2695e-01, -3.4095e-01, -8.4421e-02, -5.5420e-01,\n",
              "         -4.6714e-02,  5.4594e-01,  4.8826e-01, -4.0288e-01,  3.2868e-01,\n",
              "         -4.3262e-01, -6.4365e-01,  2.3584e-01, -3.9980e-01, -3.4872e-01,\n",
              "          1.1766e-01,  3.1077e-01,  3.7583e-01, -2.1232e-01,  1.6258e-01,\n",
              "          3.5580e-02, -1.0122e+00, -3.4095e-01, -8.5971e-02, -3.4214e-01,\n",
              "          8.8470e-02,  4.9225e-01,  1.6838e-01, -3.2967e-01,  3.0782e-01,\n",
              "          2.9514e-02, -6.2430e-01, -5.9428e-01, -8.6337e-02,  2.4391e-01,\n",
              "          6.2497e-01, -1.0320e-01,  8.9179e-01, -5.6334e-01,  3.3221e-02,\n",
              "          3.9699e-01, -6.6807e-01,  4.7009e-01,  6.5373e-01,  3.7487e-02,\n",
              "          4.3621e-01, -4.3814e-01, -1.5456e-01, -3.6689e-01,  5.0638e-01,\n",
              "          1.3468e-01, -1.7329e-01,  2.8877e-01,  5.2639e-02,  7.5540e-01,\n",
              "         -9.4672e-01, -1.1666e-01, -2.3571e-01,  6.5674e-01,  4.4904e-01,\n",
              "         -5.2828e-01, -7.6258e-02,  3.1068e-01, -3.1618e-01,  5.5931e-01,\n",
              "          2.3249e-01,  7.1707e-01, -2.6883e-01, -9.9098e-02,  3.6338e-01,\n",
              "         -1.6953e-02, -3.2006e-01,  1.1236e-01, -9.1005e-01,  1.8547e-01,\n",
              "         -3.9681e-01, -8.0114e-02,  8.7439e-01, -5.1969e-02,  4.9190e-01,\n",
              "          6.6385e-01,  2.2459e-01,  2.7024e-01,  2.5955e-01, -6.5803e-01,\n",
              "         -1.6358e-01,  9.5904e-01,  8.4632e-01,  3.5977e-02,  3.8748e-01,\n",
              "          1.0577e+00, -5.9015e-01,  6.1476e-01,  1.9408e-01, -3.4629e-01,\n",
              "          3.1935e-01, -1.6992e-01, -8.2513e-02,  2.9965e-01,  2.4305e-01,\n",
              "         -3.0251e-01,  2.7940e-01, -4.5211e-01,  1.2918e+00,  6.8060e-01,\n",
              "         -2.2236e-01,  2.6140e-01, -1.4966e-01, -9.9905e-02, -7.7831e-02,\n",
              "          8.0415e-01,  3.3408e-03,  3.6881e-01, -3.7918e-01,  3.6330e-01,\n",
              "          8.8095e-02,  2.3161e-01, -4.0559e-01, -2.5947e-01,  4.0017e-01,\n",
              "          8.2211e-02,  1.9796e-01, -3.3399e-02, -3.9642e-01,  4.0504e-01,\n",
              "          3.4401e-01, -1.6525e-01, -2.0363e-02,  3.0210e-01,  4.9893e-01,\n",
              "          3.6530e-01,  5.2715e-01, -6.1383e-02, -3.4357e-02, -3.0382e-01,\n",
              "         -1.5933e-01,  1.2893e-01,  2.8544e-01,  6.9439e-02,  2.3787e-01,\n",
              "         -4.6624e-01, -4.1072e-01,  6.7491e-02, -1.3216e-01, -2.6500e-01,\n",
              "          2.8467e-01,  2.3177e-01,  6.3134e-01,  1.9420e-01, -3.7150e-01,\n",
              "         -3.5990e-01, -8.1028e-01,  4.9549e-02,  5.7064e-01, -5.3915e-01,\n",
              "          2.6740e-01,  7.8742e-01,  3.7956e-01, -5.2029e-01,  2.7178e-02,\n",
              "          1.4043e-01, -1.8898e-01,  1.6886e-01,  2.6240e-03,  1.7889e-01,\n",
              "          2.4799e-01, -8.7507e-02, -8.5752e-01, -3.2693e-01,  3.6327e-01,\n",
              "         -3.3196e-01,  1.7464e-01,  3.2219e-01,  2.6944e-02,  8.0883e-02,\n",
              "          3.0565e-01, -1.8447e-01, -4.7688e-01, -2.6178e-01,  1.7298e-01,\n",
              "         -8.9409e-01, -7.8000e-01,  8.3690e-01,  1.2786e-02, -3.0394e-01,\n",
              "         -5.1937e-01,  6.2357e-02,  7.7699e-01, -1.3694e-02, -6.7143e-02,\n",
              "         -8.1861e-01,  1.2425e-02,  7.2409e-01,  1.3026e-01, -5.2336e-01,\n",
              "          2.9364e-01,  8.3865e-01,  2.0644e-02, -2.9196e-01, -3.1642e-01,\n",
              "         -2.8539e-01,  1.3977e-01,  1.6514e-01, -7.4721e-01, -5.2261e-01,\n",
              "          7.4854e-02,  4.5229e-01, -3.7021e-01, -1.0780e+00, -2.6287e-01,\n",
              "          9.2349e-02,  4.7154e-01, -1.5274e-01, -3.7951e-01, -3.6732e-02,\n",
              "          3.0642e-02,  6.5202e-01, -1.1298e+00,  6.3369e-02, -7.8070e-01,\n",
              "         -1.1447e+00, -2.9958e-01,  7.5440e-02, -2.6347e-01, -6.0220e-01,\n",
              "         -2.1980e-01,  2.0617e-01, -5.7879e-01]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmofJILUutqu",
        "outputId": "dfa2b6bd-a3ba-4c23-8853-31d449ce47a2"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CombinedModel(\n",
              "  (eeg_model): EncoderEEGModel(\n",
              "    (eeg_model): EEGInceptionMI(\n",
              "      (activation): ReLU()\n",
              "      (ensuredims): Ensure4d()\n",
              "      (dimshuffle): Rearrange('batch C T 1 -> batch C 1 T')\n",
              "      (initial_inception_module): _InceptionModuleMI(\n",
              "        (bottleneck): Conv2d(22, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (pooling): MaxPool2d(kernel_size=(1, 25), stride=1, padding=(0, 12), dilation=1, ceil_mode=False)\n",
              "        (pooling_conv): Conv2d(22, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (conv_list): ModuleList(\n",
              "          (0): Conv2d(48, 48, kernel_size=(1, 25), stride=(1, 1), padding=same)\n",
              "          (1): Conv2d(48, 48, kernel_size=(1, 75), stride=(1, 1), padding=same)\n",
              "          (2): Conv2d(48, 48, kernel_size=(1, 125), stride=(1, 1), padding=same)\n",
              "          (3): Conv2d(48, 48, kernel_size=(1, 175), stride=(1, 1), padding=same)\n",
              "          (4): Conv2d(48, 48, kernel_size=(1, 225), stride=(1, 1), padding=same)\n",
              "        )\n",
              "        (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (intermediate_inception_modules_1): ModuleList(\n",
              "        (0-1): 2 x _InceptionModuleMI(\n",
              "          (bottleneck): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (pooling): MaxPool2d(kernel_size=(1, 25), stride=1, padding=(0, 12), dilation=1, ceil_mode=False)\n",
              "          (pooling_conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (conv_list): ModuleList(\n",
              "            (0): Conv2d(48, 48, kernel_size=(1, 25), stride=(1, 1), padding=same)\n",
              "            (1): Conv2d(48, 48, kernel_size=(1, 75), stride=(1, 1), padding=same)\n",
              "            (2): Conv2d(48, 48, kernel_size=(1, 125), stride=(1, 1), padding=same)\n",
              "            (3): Conv2d(48, 48, kernel_size=(1, 175), stride=(1, 1), padding=same)\n",
              "            (4): Conv2d(48, 48, kernel_size=(1, 225), stride=(1, 1), padding=same)\n",
              "          )\n",
              "          (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (residual_block_1): _ResidualModuleMI(\n",
              "        (activation): ReLU()\n",
              "        (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv): Conv2d(22, 288, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (intermediate_inception_modules_2): ModuleList(\n",
              "        (0-2): 3 x _InceptionModuleMI(\n",
              "          (bottleneck): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (pooling): MaxPool2d(kernel_size=(1, 25), stride=1, padding=(0, 12), dilation=1, ceil_mode=False)\n",
              "          (pooling_conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (conv_list): ModuleList(\n",
              "            (0): Conv2d(48, 48, kernel_size=(1, 25), stride=(1, 1), padding=same)\n",
              "            (1): Conv2d(48, 48, kernel_size=(1, 75), stride=(1, 1), padding=same)\n",
              "            (2): Conv2d(48, 48, kernel_size=(1, 125), stride=(1, 1), padding=same)\n",
              "            (3): Conv2d(48, 48, kernel_size=(1, 175), stride=(1, 1), padding=same)\n",
              "            (4): Conv2d(48, 48, kernel_size=(1, 225), stride=(1, 1), padding=same)\n",
              "          )\n",
              "          (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (residual_block_2): _ResidualModuleMI(\n",
              "        (activation): ReLU()\n",
              "        (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (ave_pooling): AvgPool2d(kernel_size=(1, 1125), stride=(1, 1125), padding=0)\n",
              "      (flat): Flatten(start_dim=1, end_dim=-1)\n",
              "      (final_layer): Sequential(\n",
              "        (fc): Linear(in_features=288, out_features=768, bias=True)\n",
              "        (out_fun): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (gpt2_model): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2EneAGW3uttM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sBSH_fmQutvL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}